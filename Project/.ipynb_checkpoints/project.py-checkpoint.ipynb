{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "# # The following line is needed to show plots inline in notebooks\n",
    "# %matplotlib inline \n",
    "# from sklearn.preprocessing import StandardScaler, LabelBinarizer\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.model_selection import KFold\n",
    "# from sklearn.metrics import make_scorer, confusion_matrix\n",
    "# from sklearn.model_selection import learning_curve\n",
    "# import seaborn as sns\n",
    "# sns.set_style('whitegrid')\n",
    "# import statsmodels.api as sm\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# from sklearn.feature_selection import RFE\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# # Import the necessary libraries first\n",
    "# from sklearn.feature_selection import SelectKBest\n",
    "# from sklearn.feature_selection import chi2\n",
    "# from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claim</th>\n",
       "      <th>claimant</th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>related_articles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A line from George Orwell's novel 1984 predict...</td>\n",
       "      <td></td>\n",
       "      <td>2017-07-17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[122094, 122580, 130685, 134765]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Maine legislature candidate Leslie Gibson insu...</td>\n",
       "      <td></td>\n",
       "      <td>2018-03-17</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[106868, 127320, 128060]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A 17-year-old girl named Alyssa Carson is bein...</td>\n",
       "      <td></td>\n",
       "      <td>2018-07-18</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>[132130, 132132, 149722]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In 1988 author Roald Dahl penned an open lette...</td>\n",
       "      <td></td>\n",
       "      <td>2019-02-04</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>[123254, 123418, 127464]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>When it comes to fighting terrorism, \"Another ...</td>\n",
       "      <td>Hillary Clinton</td>\n",
       "      <td>2016-03-22</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>[41099, 89899, 72543, 82644, 95344, 88361]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               claim         claimant  \\\n",
       "0  A line from George Orwell's novel 1984 predict...                    \n",
       "1  Maine legislature candidate Leslie Gibson insu...                    \n",
       "2  A 17-year-old girl named Alyssa Carson is bein...                    \n",
       "3  In 1988 author Roald Dahl penned an open lette...                    \n",
       "4  When it comes to fighting terrorism, \"Another ...  Hillary Clinton   \n",
       "\n",
       "        date  id  label                            related_articles  \n",
       "0 2017-07-17   0      0            [122094, 122580, 130685, 134765]  \n",
       "1 2018-03-17   1      2                    [106868, 127320, 128060]  \n",
       "2 2018-07-18   4      1                    [132130, 132132, 149722]  \n",
       "3 2019-02-04   5      2                    [123254, 123418, 127464]  \n",
       "4 2016-03-22   6      2  [41099, 89899, 72543, 82644, 95344, 88361]  "
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basePath = os.path.dirname(os.path.abspath(\"train.json\"))\n",
    "# 0:false, 1:partly true, 2:true\n",
    "claim = pd.read_json(open(basePath + \"/train/train.json\", \"r\", encoding=\"utf8\"))\n",
    "claim.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "txtPath = basePath+\"/train/train_articles/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def appendArticles(articleList, basePath):\n",
    "    contents = ''\n",
    "    for articleNumber in articleList:\n",
    "        f = open(basePath+str(articleNumber)+\".txt\", \"r\")\n",
    "        contents = f.read()+\";\"+contents\n",
    "        f.close()\n",
    "    return contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "claim['articleText'] = claim.apply(lambda row: appendArticles(row['related_articles'], txtPath) ,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assignLength(row, colName):\n",
    "    return len(row[colName])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claim</th>\n",
       "      <th>claimant</th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>related_articles</th>\n",
       "      <th>articleText</th>\n",
       "      <th>articleLength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A line from George Orwell's novel 1984 predict...</td>\n",
       "      <td></td>\n",
       "      <td>2017-07-17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[122094, 122580, 130685, 134765]</td>\n",
       "      <td>1984 by George Orwell\\n1984 is a dystopian nov...</td>\n",
       "      <td>7043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Maine legislature candidate Leslie Gibson insu...</td>\n",
       "      <td></td>\n",
       "      <td>2018-03-17</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[106868, 127320, 128060]</td>\n",
       "      <td>Maine candidate apologizes after calling Parkl...</td>\n",
       "      <td>9447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A 17-year-old girl named Alyssa Carson is bein...</td>\n",
       "      <td></td>\n",
       "      <td>2018-07-18</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>[132130, 132132, 149722]</td>\n",
       "      <td>About Kennedy Space Center Visitor Complex\\nDe...</td>\n",
       "      <td>16891</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               claim claimant       date  id  \\\n",
       "0  A line from George Orwell's novel 1984 predict...          2017-07-17   0   \n",
       "1  Maine legislature candidate Leslie Gibson insu...          2018-03-17   1   \n",
       "2  A 17-year-old girl named Alyssa Carson is bein...          2018-07-18   4   \n",
       "\n",
       "   label                  related_articles  \\\n",
       "0      0  [122094, 122580, 130685, 134765]   \n",
       "1      2          [106868, 127320, 128060]   \n",
       "2      1          [132130, 132132, 149722]   \n",
       "\n",
       "                                         articleText  articleLength  \n",
       "0  1984 by George Orwell\\n1984 is a dystopian nov...           7043  \n",
       "1  Maine candidate apologizes after calling Parkl...           9447  \n",
       "2  About Kennedy Space Center Visitor Complex\\nDe...          16891  "
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "claim['articleLength'] = claim.apply(lambda row: assignLength(row, 'articleText'), axis=1)\n",
    "claim.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = claim['label']\n",
    "# Drop the `label` column\n",
    "claim = claim.drop(\"label\", axis=1)\n",
    "# Make training and test sets \n",
    "X_train, X_test, y_train, y_test = train_test_split(claim['articleText'], y, test_size=0.33, random_state=53)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the `count_vectorizer` \n",
    "count_vectorizer = CountVectorizer(stop_words='english')\n",
    "\n",
    "# Fit and transform the training data \n",
    "count_train = count_vectorizer.fit_transform(X_train) \n",
    "\n",
    "# Transform the test set \n",
    "count_test = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the feature names of `tfidf_vectorizer` \n",
    "print(count_vectorizer.get_feature_names()[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = claim.label \n",
    "\n",
    "# Drop the `label` column\n",
    "claim.drop(\"label\", axis=1)\n",
    "\n",
    "# Make training and test sets \n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], y, test_size=0.33, random_state=53)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8476</th>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10294</th>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3608</th>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10142</th>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        title  \\\n",
       "Unnamed: 0                                                      \n",
       "8476                             You Can Smell Hillary’s Fear   \n",
       "10294       Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "3608              Kerry to go to Paris in gesture of sympathy   \n",
       "10142       Bernie supporters on Twitter erupt in anger ag...   \n",
       "875          The Battle of New York: Why This Primary Matters   \n",
       "\n",
       "                                                         text label  \n",
       "Unnamed: 0                                                           \n",
       "8476        Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
       "10294       Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n",
       "3608        U.S. Secretary of State John F. Kerry said Mon...  REAL  \n",
       "10142       — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n",
       "875         It's primary day in New York and front-runners...  REAL  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('fake_or_real_news.csv')\n",
    "test = test.set_index(\"Unnamed: 0\")\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set `y` \n",
    "y = df.label \n",
    "\n",
    "# Drop the `label` column\n",
    "df.drop(\"label\", axis=1)\n",
    "\n",
    "# Make training and test sets \n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], y, test_size=0.33, random_state=53)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the `count_vectorizer` \n",
    "count_vectorizer = CountVectorizer(stop_words='english')\n",
    "\n",
    "# Fit and transform the training data \n",
    "count_train = count_vectorizer.fit_transform(X_train) \n",
    "\n",
    "# Transform the test set \n",
    "count_test = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the `tfidf_vectorizer` \n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_df=0.7) \n",
    "\n",
    "# Fit and transform the training data \n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train) \n",
    "\n",
    "# Transform the test set \n",
    "tfidf_test = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['حلب', 'عربي', 'عن', 'لم', 'ما', 'محاولات', 'من', 'هذا', 'والمرضى', 'ยงade']\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_vectorizer.get_feature_names()[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00', '000', '0000', '00000031', '000035', '00006', '0001', '0001pt', '000ft', '000km']\n"
     ]
    }
   ],
   "source": [
    "print(count_vectorizer.get_feature_names()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_df = pd.DataFrame(count_train.A, columns=count_vectorizer.get_feature_names())\n",
    "tfidf_df = pd.DataFrame(tfidf_train.A, columns=tfidf_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difference = set(count_df.columns) - set(tfidf_df.columns)\n",
    "difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(count_df.equals(tfidf_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['1924', '1925', '1926', '1927', '1928', '1929', '193', '1930', '1930s',\n",
       "       '1931', '1932', '1933', '1934', '1935', '1936', '1937', '1938', '1939',\n",
       "       '194', '1940', '1940s', '1941', '1942', '1943', '1944', '1945', '1946',\n",
       "       '1947', '1948', '1949', '195', '1950', '1950s', '1951', '1952', '1953',\n",
       "       '1954', '1955', '1956', '1957', '1958', '19580395003', '19580405001',\n",
       "       '1959', '196', '1960', '1960s', '1961', '19617315012', '1962'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_df.columns[500:550]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>0000</th>\n",
       "      <th>00000031</th>\n",
       "      <th>000035</th>\n",
       "      <th>00006</th>\n",
       "      <th>0001</th>\n",
       "      <th>0001pt</th>\n",
       "      <th>000ft</th>\n",
       "      <th>000km</th>\n",
       "      <th>...</th>\n",
       "      <th>حلب</th>\n",
       "      <th>عربي</th>\n",
       "      <th>عن</th>\n",
       "      <th>لم</th>\n",
       "      <th>ما</th>\n",
       "      <th>محاولات</th>\n",
       "      <th>من</th>\n",
       "      <th>هذا</th>\n",
       "      <th>والمرضى</th>\n",
       "      <th>ยงade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56922 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  000  0000  00000031  000035  00006  0001  0001pt  000ft  000km  ...  \\\n",
       "0   0    0     0         0       0      0     0       0      0      0  ...   \n",
       "1   0    0     0         0       0      0     0       0      0      0  ...   \n",
       "2   0    0     0         0       0      0     0       0      0      0  ...   \n",
       "3   0    0     0         0       0      0     0       0      0      0  ...   \n",
       "4   0    0     0         0       0      0     0       0      0      0  ...   \n",
       "\n",
       "   حلب  عربي  عن  لم  ما  محاولات  من  هذا  والمرضى  ยงade  \n",
       "0    0     0   0   0   0        0   0    0        0      0  \n",
       "1    0     0   0   0   0        0   0    0        0      0  \n",
       "2    0     0   0   0   0        0   0    0        0      0  \n",
       "3    0     0   0   0   0        0   0    0        0      0  \n",
       "4    0     0   0   0   0        0   0    0        0      0  \n",
       "\n",
       "[5 rows x 56922 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4244"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(count_train.A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4244, 56922)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_df = pd.DataFrame(count_train.A, columns=count_vectorizer.get_feature_names())\n",
    "count_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']\n",
      "(4, 9)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "corpus = ['This is the first document.',\n",
    "          'This document is the second document.',\n",
    "          'And this is the third one.',\n",
    "          'Is this the first document?']\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "print(vectorizer.get_feature_names())\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4x9 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 21 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
