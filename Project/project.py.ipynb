{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# # The following line is needed to show plots inline in notebooks\n",
    "# %matplotlib inline \n",
    "# from sklearn.preprocessing import StandardScaler, LabelBinarizer\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# from sklearn.model_selection import KFold\n",
    "# from sklearn.metrics import make_scorer, confusion_matrix\n",
    "# from sklearn.model_selection import learning_curve\n",
    "# import seaborn as sns\n",
    "# sns.set_style('whitegrid')\n",
    "# import statsmodels.api as sm\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# from sklearn.feature_selection import RFE\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# # Import the necessary libraries first\n",
    "# from sklearn.feature_selection import SelectKBest\n",
    "# from sklearn.feature_selection import chi2\n",
    "# from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claim</th>\n",
       "      <th>claimant</th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>related_articles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A line from George Orwell's novel 1984 predict...</td>\n",
       "      <td></td>\n",
       "      <td>2017-07-17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[122094, 122580, 130685, 134765]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Maine legislature candidate Leslie Gibson insu...</td>\n",
       "      <td></td>\n",
       "      <td>2018-03-17</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[106868, 127320, 128060]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A 17-year-old girl named Alyssa Carson is bein...</td>\n",
       "      <td></td>\n",
       "      <td>2018-07-18</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>[132130, 132132, 149722]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In 1988 author Roald Dahl penned an open lette...</td>\n",
       "      <td></td>\n",
       "      <td>2019-02-04</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>[123254, 123418, 127464]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>When it comes to fighting terrorism, \"Another ...</td>\n",
       "      <td>Hillary Clinton</td>\n",
       "      <td>2016-03-22</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>[41099, 89899, 72543, 82644, 95344, 88361]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               claim         claimant  \\\n",
       "0  A line from George Orwell's novel 1984 predict...                    \n",
       "1  Maine legislature candidate Leslie Gibson insu...                    \n",
       "2  A 17-year-old girl named Alyssa Carson is bein...                    \n",
       "3  In 1988 author Roald Dahl penned an open lette...                    \n",
       "4  When it comes to fighting terrorism, \"Another ...  Hillary Clinton   \n",
       "\n",
       "        date  id  label                            related_articles  \n",
       "0 2017-07-17   0      0            [122094, 122580, 130685, 134765]  \n",
       "1 2018-03-17   1      2                    [106868, 127320, 128060]  \n",
       "2 2018-07-18   4      1                    [132130, 132132, 149722]  \n",
       "3 2019-02-04   5      2                    [123254, 123418, 127464]  \n",
       "4 2016-03-22   6      2  [41099, 89899, 72543, 82644, 95344, 88361]  "
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basePath = os.path.dirname(os.path.abspath(\"train.json\"))\n",
    "# 0:false, 1:partly true, 2:true\n",
    "claim = pd.read_json(open(basePath + \"/train/train.json\", \"r\", encoding=\"utf8\"))\n",
    "claim.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "txtPath = basePath+\"/train/train_articles/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def appendArticles(articleList, basePath):\n",
    "    contents = ''\n",
    "    for articleNumber in articleList:\n",
    "        f = open(basePath+str(articleNumber)+\".txt\", \"r\")\n",
    "        contents = f.read()+\";\"+contents\n",
    "        f.close()\n",
    "    return contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "claim['articleText'] = claim.apply(lambda row: appendArticles(row['related_articles'], txtPath) ,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assignLength(row, colName):\n",
    "    return len(row[colName])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claim</th>\n",
       "      <th>claimant</th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>related_articles</th>\n",
       "      <th>articleText</th>\n",
       "      <th>articleLength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A line from George Orwell's novel 1984 predict...</td>\n",
       "      <td></td>\n",
       "      <td>2017-07-17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[122094, 122580, 130685, 134765]</td>\n",
       "      <td>1984 by George Orwell\\n1984 is a dystopian nov...</td>\n",
       "      <td>7043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Maine legislature candidate Leslie Gibson insu...</td>\n",
       "      <td></td>\n",
       "      <td>2018-03-17</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[106868, 127320, 128060]</td>\n",
       "      <td>Maine candidate apologizes after calling Parkl...</td>\n",
       "      <td>9447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A 17-year-old girl named Alyssa Carson is bein...</td>\n",
       "      <td></td>\n",
       "      <td>2018-07-18</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>[132130, 132132, 149722]</td>\n",
       "      <td>About Kennedy Space Center Visitor Complex\\nDe...</td>\n",
       "      <td>16891</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               claim claimant       date  id  \\\n",
       "0  A line from George Orwell's novel 1984 predict...          2017-07-17   0   \n",
       "1  Maine legislature candidate Leslie Gibson insu...          2018-03-17   1   \n",
       "2  A 17-year-old girl named Alyssa Carson is bein...          2018-07-18   4   \n",
       "\n",
       "   label                  related_articles  \\\n",
       "0      0  [122094, 122580, 130685, 134765]   \n",
       "1      2          [106868, 127320, 128060]   \n",
       "2      1          [132130, 132132, 149722]   \n",
       "\n",
       "                                         articleText  articleLength  \n",
       "0  1984 by George Orwell\\n1984 is a dystopian nov...           7043  \n",
       "1  Maine candidate apologizes after calling Parkl...           9447  \n",
       "2  About Kennedy Space Center Visitor Complex\\nDe...          16891  "
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "claim['articleLength'] = claim.apply(lambda row: assignLength(row, 'articleText'), axis=1)\n",
    "claim.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = claim['label']\n",
    "# Drop the `label` column\n",
    "claim = claim.drop(\"label\", axis=1)\n",
    "# Make training and test sets \n",
    "X_train, X_test, y_train, y_test = train_test_split(claim['articleText'], y, test_size=0.33, random_state=53)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the `count_vectorizer` \n",
    "count_vectorizer = CountVectorizer(stop_words='english')\n",
    "\n",
    "# Fit and transform the training data \n",
    "count_train = count_vectorizer.fit_transform(X_train) \n",
    "\n",
    "# Transform the test set \n",
    "count_test = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ﻼد', 'ﻼﺗﻪ', '𝑩𝒓𝒂𝒕𝒎𝒂𝒏', '𝑫𝒐𝒖𝒈', '𝔸𝕡𝕖𝕝', '𝕁ℙ', '𝕄𝕔𝔾𝕝𝕠𝕟𝕖', '𝕋𝕙𝕖𝕣𝕖𝕤𝕖', '𝖑𝖎𝖑𝖆', '𝖗𝖔𝖘𝖎𝖊']\n"
     ]
    }
   ],
   "source": [
    "# Get the feature names of `tfidf_vectorizer` \n",
    "print(count_vectorizer.get_feature_names()[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the `tfidf_vectorizer` \n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_df=0.7) \n",
    "\n",
    "# Fit and transform the training data \n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train) \n",
    "\n",
    "# Transform the test set \n",
    "tfidf_test = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ﻼد', 'ﻼﺗﻪ', '𝑩𝒓𝒂𝒕𝒎𝒂𝒏', '𝑫𝒐𝒖𝒈', '𝔸𝕡𝕖𝕝', '𝕁ℙ', '𝕄𝕔𝔾𝕝𝕠𝕟𝕖', '𝕋𝕙𝕖𝕣𝕖𝕤𝕖', '𝖑𝖎𝖑𝖆', '𝖗𝖔𝖘𝖎𝖊']\n"
     ]
    }
   ],
   "source": [
    "# Get the feature names of `tfidf_vectorizer` \n",
    "print(tfidf_vectorizer.get_feature_names()[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_df = pd.DataFrame(count_train.A, columns=count_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_df = pd.DataFrame(tfidf_train.A, columns=tfidf_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference = set(count_df.columns) - set(tfidf_df.columns)\n",
    "difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(count_df.equals(tfidf_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bag of words feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.580\n"
     ]
    }
   ],
   "source": [
    "clf.fit(count_train, y_train)\n",
    "pred = clf.predict(count_test)\n",
    "score = accuracy_score(y_test, pred)\n",
    "print(\"accuracy:   %0.3f\" % score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf-idf features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.590\n"
     ]
    }
   ],
   "source": [
    "clf.fit(tfidf_train, y_train)\n",
    "pred = clf.predict(tfidf_test)\n",
    "score = accuracy_score(y_test, pred)\n",
    "print(\"accuracy:   %0.3f\" % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
